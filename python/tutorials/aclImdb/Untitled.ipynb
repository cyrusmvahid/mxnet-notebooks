{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports and env-variable\n",
    "import numpy as mp\n",
    "import os\n",
    "import glob\n",
    "import nltk\n",
    "from nltk.tokenize.moses import MosesTokenizer\n",
    "import urllib3\n",
    "import tarfile\n",
    "\n",
    "BASE_DIR = '/home/ubuntu/CyrusProjects/mxnet-notebooks/python/tutorials'\n",
    "PATH='/aclImdb'\n",
    "\n",
    "with open('aclImdb/imdb.vocab') as vocab_file:\n",
    "    vocab_array = vocab_file.readlines()\n",
    "vocab_array = [x.strip() for x in vocab_array]\n",
    "print(len(vocab_array))\n",
    "\n",
    "\n",
    "with open(BASE_DIR + PATH + '/imdb.vocab') as f:\n",
    "    dic = f.readlines()\n",
    "dic= [x.strip() for x in dic]\n",
    "dic = np.array(np.sort(dic))\n",
    "dic = np.unique(dic)\n",
    "dic = dic.tolist()\n",
    "print(dic)\n",
    "\n",
    "# tokenizer.perl is from Moses: https://github.com/moses-smt/mosesdecoder/tree/master/scripts/tokenizer\n",
    "def sentence_array_creator(path, root_dir):\n",
    "    os.chdir(path)\n",
    "    sentences = []\n",
    "    for file in list(glob.glob(\"*.txt\")):\n",
    "        with open(file, 'r') as f:\n",
    "            sentences.append(f.readline().strip().lower())\n",
    "    return sentences\n",
    "    os.chdir(root_dir)\n",
    "\n",
    "os.chdir(BASE_DIR)\n",
    "root_dir = os.getcwd()\n",
    "\n",
    "base_dir = root_dir + path\n",
    "pos_train_path = base_dir + '/train/pos'\n",
    "neg_train_path = base_dir + '/train/neg'\n",
    "pos_test_path = base_dir + '/test/pos'\n",
    "neg_test_path = base_dir + '/test/neg'\n",
    "\n",
    "\n",
    "pos_train_sentences = sentence_array_creator(pos_train_path, root_dir)\n",
    "neg_train_sentences = sentence_array_creator(neg_train_path, root_dir)\n",
    "pos_test_sentences = sentence_array_creator(pos_test_path, root_dir)\n",
    "neg_test_sentences = sentence_array_creator(neg_test_path, root_dir)\n",
    "print('{}; {}; {}; {}; '.format)\n",
    "\n",
    "print(\"{}, {}, {}, {}\".format(len(pos_train_sentences), len(neg_train_sentences), len(pos_test_sentences), len(neg_test_sentences)))\n",
    "\n",
    "\n",
    "def get_dic_index(word, dic):\n",
    "    try:\n",
    "        ret_val = dic.index(word)\n",
    "    except ValueError: \n",
    "        ret_val = -1\n",
    "    return ret_val\n",
    "\n",
    "    \n",
    "word = \"is\"\n",
    "print(get_dic_index(word, dic))\n",
    "\n",
    "def sentence_encoder(sentences, vocab):\n",
    "    bow = []\n",
    "    t = RegexpTokenizer(r'\\w+')\n",
    "    prog = 0\n",
    "    for sentence in sentences:\n",
    "        if prog % 10 == 0:\n",
    "            print(prog, sep=' # ', end='DONE', flush=True)\n",
    "            prog += 1\n",
    "        s = ''.join(sentence)\n",
    "        tokens = t.tokenize(s)\n",
    "        indexes = []\n",
    "        for token in tokens:\n",
    "            idx = get_dic_index(token, vocab)\n",
    "            if idx != -1:\n",
    "                indexes.append(idx)\n",
    "        bow.append(indexes)\n",
    "    return bow\n",
    "\n",
    "def sentence_tokenizer(sentences):\n",
    "    bow = []\n",
    "    t = RegexpTokenizer(r'\\w+')\n",
    "    for sentence in sentences:\n",
    "        s = ''.join(sentence)\n",
    "        tokens = t.tokenize(s)\n",
    "        bow.append(tokens)\n",
    "    return bow\n",
    "\n",
    "\n",
    "def print_items(array):\n",
    "    for i in array:\n",
    "        print('{} \\n'.format(i))\n",
    "        \n",
    "sentences = [\n",
    "                [\"elizabeth ashley is receiving phone calls from her nephew michael--he's crying, screaming and asking for help. the problem is michael died 15 years ago. <br /><br />this film scared me silly back in 1972 when it aired on abc. seeing it again, years later, it still works.<br /><br />the movie is a little slow and predictable, the deaths are very tame and there's a tacked-on happy ending, but this is a tv movie so you have to give it room. elizabeth ashley is excellent, ben gazzara is ok and it's fun to see michael douglas so young. and those telephone calls still scare the living daylights out of me. i actually had to turn a light on during one of them!<br /><br />a creepy little tv movie. worth seeing.\"],\n",
    "                [\"big fat liar is the best movie ever! it is funny, and cool. jason shepherd (frankie muniz) proves that he was not lying and goes to los angeles to get his paper back from marty wolf( paul giamatti). along with friend kaylee(amanda bynes), mess up his life since marty won't call jasons' dad and say he wrote the paper! yet it all turns out good and is a good movie to watch!\"],\n",
    "                [\"out of any category, this is one demented and over the edge film, even in todays standards. filmed entirely in crap-o-rama, this film will blow your mind (and something else too!)<br /><br />the amount of hilarious bad taste and sleaze is astonishing. the dialog is breathtakingly fast and campy. you'll either love or hate this film, but give it go. i've seen it 4 times and absolutely love it. divine is in the quest for being the filthiest person alive, but so are her rivals too in this obscene and disgusting (but funny) and stylish little film. <br /><br />divine was phenomenal, and she will always be missed greatly. edith massey does the unforgettable performance as the egglady and don't forget the energetic mink stole!<br /><br />Ã¼ber crazy s**t! <br /><br />recommended also for you sick little puppies;<br /><br />female trouble <br /><br />desperate living <br /><br />polyester\"]\n",
    "            ]\n",
    "\n",
    "sentences = pos_train_sentences\n",
    "st = sentence_tokenizer(sentences)\n",
    "#print_items(st)\n",
    "\n",
    "\n",
    "st1 = sentence_encoder(sentences, dic)\n",
    "#print_items(st)\n",
    "\n",
    "\n",
    "bow_pos_train_sentences = sentence_embedding(pos_train_sentences)\n",
    "bow_neg_train_sentences = sentence_embedding(neg_train_sentences)\n",
    "bow_pos_test_sentences = sentence_embedding(pos_test_sentences)\n",
    "bow_neg_test_sentences = sentence_embedding(neg_test_sentences)\n",
    "\n",
    "print(len(bow_neg_test_sentences))\n",
    "print(len(bow_neg_train_sentences))\n",
    "print(len(bow_pos_test_sentences))\n",
    "print(len(bow_pos_train_sentences))\n",
    "np.save(BASE_DIR + PATH + '/bow_neg_test_sentences_batch', bow_neg_test_sentences)\n",
    "np.save(BASE_DIR + PATH + '/bow_neg_train_sentences_batch', bow_neg_train_sentences)\n",
    "np.save(BASE_DIR + PATH + '/bow_pos_test_sentences_batch', bow_pos_test_sentences)\n",
    "np.save(BASE_DIR + PATH + '/bow_pos_train_sentences_batch', bow_pos_train_sentences)\n",
    "\n",
    "\n",
    "print(len(np.load(BASE_DIR + PATH + '/bow_neg_test_sentences_batch.npy')))\n",
    "print(len(np.load(BASE_DIR + PATH + '/bow_neg_train_sentences_batch.npy')))\n",
    "print(len(np.load(BASE_DIR + PATH + '/bow_pos_test_sentences_batch.npy')))\n",
    "print(len(np.load(BASE_DIR + PATH + '/bow_pos_train_sentences_batch.npy')))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
